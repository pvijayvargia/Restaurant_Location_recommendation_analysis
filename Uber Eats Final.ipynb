{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d0b4f2-1a1f-4a22-b3c6-f58b393f35b5",
   "metadata": {},
   "source": [
    "# Web Scrapping uber eats website\n",
    "Here, we scrap the data from uber eats website to gather information about restraunts in san francisco. We get the following information for  restraunts in SF across different price ranges. We also scrape the information about their addres, how many ratings they have received, what is their overall rating out of 5 and the cuicine they serve. Our goal is to scrape data from yelp and uber eats and answer the following business question - A real estate agent in Sanfrancisco is considering opening a restaurant and wants to determine the best neighborhood, cuicine and price range for the reataurant. The agent wants to gather the data about existing restaurants in SF and find out the ideal combination of neighborhood, cuicine type and prcie range that would likely attract customers and ensure the success of the restraunt venture in SF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e86fbe96-1ad3-4fed-b8c2-f28af9a5ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "import mysql.connector\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ae2b1-6aec-4a6d-8115-202090bb1f07",
   "metadata": {},
   "source": [
    "Using Selenium to load the uber eats page and apply filte price - $. After we will be saving the page in the directory 'Uber Eats'. Will be using reading this file later and use beautiful soup and regex to get scrape the website and get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efbc481e-d786-48f2-a800-952c4c1c3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an isntance for chrome webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Navigating to Uber eats\n",
    "driver.get('https://www.ubereats.com/find-near-me/san-francisco-ca/food') \n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "dollar_1 = driver.find_element(By.CSS_SELECTOR, '[data-baseweb=\"button\"]')\n",
    "dollar_1.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#creating the directory\n",
    "import os\n",
    "directory = 'Uber Eats Web scrapping'\n",
    "\n",
    "#Checking if the directory exists\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "#Saving the web page\n",
    "html_source = driver.page_source\n",
    "with open(os.path.join(directory,'Uber_Eats_1_dollar_rest.html'), 'w', encoding='utf-8') as file:\n",
    "    file.write(html_source)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "278eaec6-71be-4c02-93aa-ecbec001820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "#Opening the page and parsing into html.\n",
    "from bs4 import BeautifulSoup\n",
    "with open(os.path.join(directory,'Uber_Eats_1_dollar_rest.html'), 'r', encoding='utf-8') as file:\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "#Using beautiful soup to extract required information\n",
    "\n",
    "#Starting with storing all the data for each restaurant in a list object\n",
    "output_list = []\n",
    "for x in soup.findAll('div', class_ = 'al br am l0 lw'):\n",
    "    output = x.text\n",
    "    output_list.append(output)\n",
    "\n",
    "#print(output_list)\n",
    "\n",
    "#Now extracting restaurant name by extracting all the values before the $ sign in each element. We will iterate over each object\n",
    "retaurant_names = []\n",
    "\n",
    "for item in output_list:\n",
    "    #find the position of dollar sign\n",
    "    dollar_index = item.find('$')\n",
    "    \n",
    "    if dollar_index != -1:\n",
    "        #Extract the restuarant name before '$' sign\n",
    "        retaurant_name = item[:dollar_index].strip()\n",
    "        retaurant_names.append(retaurant_name)\n",
    "\n",
    "#print(retaurant_names)\n",
    "print(len(retaurant_names))\n",
    "\n",
    "\n",
    "#Now extracting address by extracting information between 'Location marker' and 'Delivery..'. We will iterate over each object\n",
    "addresses = []\n",
    "\n",
    "for item in output_list:\n",
    "    #find the position of Location Marker\n",
    "    lm_index = item.find('Location marker')\n",
    "    \n",
    "    if lm_index != -1:\n",
    "        #find the position of 'Delivery'\n",
    "        delivery_index = item.find('Delivery')\n",
    "        #Extract the address info\n",
    "        addresse = item[lm_index + len('Location Marker') :delivery_index].strip()\n",
    "        addresses.append(addresse)\n",
    "\n",
    "#print(addresses)\n",
    "print(len(addresses))\n",
    "\n",
    "#Now extracting zipcodes from addresses using regex\n",
    "zipcodes = []\n",
    "zip_pattern = r'\\b\\d{5}(?:-\\d{4})?\\b'\n",
    "\n",
    "for address in addresses:\n",
    "    match = re.search(zip_pattern, address)\n",
    "    \n",
    "    if match:\n",
    "        zipcodes.append(match.group())\n",
    "    else:\n",
    "        zipcodes.append(0)\n",
    "        \n",
    "#print(zipcodes)\n",
    "print(len(zipcodes))\n",
    "\n",
    "#Now fetching the details of review_count using regex\n",
    "reviews = []\n",
    "\n",
    "review_pattern = re.compile(r'\\((\\d+\\+?) ratings\\)')\n",
    "\n",
    "#Iterate over output_list\n",
    "for element in output_list:\n",
    "    #Search for 'ratings' in the element\n",
    "    match = review_pattern.search(element)\n",
    "    if match:\n",
    "        #If ratings found, extract the number within the brackets\n",
    "        review = match.group(1)\n",
    "        reviews.append(review)\n",
    "    else:\n",
    "        #If rating not found, return 'new'\n",
    "        reviews.append('new')\n",
    "\n",
    "#print(reviews)\n",
    "print(len(reviews))\n",
    "\n",
    "#Now extracting cuisine form this list\n",
    "cuisine_list = []\n",
    "\n",
    "#Iterate over each element in output_list\n",
    "for element in output_list:\n",
    "    #Search for the substring after 'Circle i' using regex\n",
    "    match = re.search(r'Circle i(\\w+)(?=\\W|$)', element)\n",
    "    if match:\n",
    "        cuicine_info = match.group(1)\n",
    "        #split the cuicine info by non-alphanumeric characters and filter out empty strings\n",
    "        cuisines = [c.strip() for c in re.split(r'\\W+', cuicine_info) if c.strip()]\n",
    "        cuisine_list.append(cuisines)\n",
    "   \n",
    "#print(cuisine_list)\n",
    "print(len(cuisine_list))\n",
    "\n",
    "#Now extracting the rating informaation using regex \n",
    "rating_pattern = r'(\\d+(\\.\\d+)?)\\s*\\([0-9]+\\s*ratings\\)'\n",
    "\n",
    "ratings = []\n",
    "#Iterate over output_list\n",
    "for element in output_list:\n",
    "    match = re.search(rating_pattern, element)\n",
    "    if match:\n",
    "        rating = match.group(1)\n",
    "        ratings.append(rating)\n",
    "    else:\n",
    "        ratings.append('0')\n",
    "\n",
    "#print(ratings)\n",
    "print(len(ratings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fe13534-1e4c-43f3-8908-69f58040357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': ('0df63a9290', 'Taqueria Cazadores', '1600 Mission St, San Francisco, CA 94103', 'S', '94103', '32', ['Mexican'], '4.7', '$')}\n"
     ]
    }
   ],
   "source": [
    "#Creating a data dictionary\n",
    "\n",
    "#Creating unique id\n",
    "id = [uuid.uuid4().hex[:10] for _ in range(300)]\n",
    "\n",
    "data_dict = {\n",
    "    'id': id,\n",
    "    'name' : retaurant_names,\n",
    "    'Address' : addresses,\n",
    "    'city': 'San Francisco',\n",
    "    'zip_code': zipcodes,\n",
    "    'review_count': reviews,\n",
    "    'categories': cuisine_list,\n",
    "    'rating': ratings,\n",
    "    'price': '$'\n",
    "\n",
    "}\n",
    "\n",
    "data = dict(zip(data_dict.keys(), zip(*data_dict.values())))\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36830db2-73c2-4c3f-a53e-8af75a6c8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a SQL table\n",
    "def create_sql_table(db_name, table_name, table_info):\n",
    "    try:\n",
    "        # Connect to server\n",
    "        conn = mysql.connector.connect(host='127.0.0.1',\n",
    "                                       port = '3306',\n",
    "                                       user='root',\n",
    "                                       password='Pvv@399051')\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Create database if it doesn't exist\n",
    "        cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "        \n",
    "        # Create table if it doesn't exist\n",
    "        cursor.execute(f\"CREATE TABLE IF NOT EXISTS {db_name}.{table_name} {table_info}\")\n",
    "        \n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Something went wrong:\", err)\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# Function to insert data into the table\n",
    "def insert_data_dict(db_name, table_name, data_dict):\n",
    "    try:\n",
    "        #Connect to MySQL database\n",
    "        conn = mysql.connector.connect(host='127.0.0.1',\n",
    "                                       port = '3306',\n",
    "                                       user='root',\n",
    "                                       password='Pvv@399051', database=db_name)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        #Find the max length among all values\n",
    "        max_length = max(len(lst) if isinstance(lst,list) else 1 for lst in data_dict.values())\n",
    "        \n",
    "        #Fill missing values with None or empty string\n",
    "        for key, value in data_dict.items():\n",
    "            if not isinstance(value,list):\n",
    "                data_dict[key] = [value] * max_length\n",
    "            elif len(value) < max_length:\n",
    "                data_dict[key].extend([None]*(max_legth - len(values)))\n",
    "                \n",
    "        #Create a parameterised sql query\n",
    "        placeholders = ', '.join(['%s'] * len(data_dict))\n",
    "        columns = ', '.join(data_dict.keys())\n",
    "        sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "        \n",
    "        #Prepare the data values to be inserted\n",
    "        values = [tuple(data_dict[key][i] for key in data_dict) for i in range(max_length)]\n",
    "        \n",
    "        #Execute the query with the values from the data dictionary\n",
    "        cursor.executemany(sql, values)\n",
    "\n",
    "        #Commit the transaction\n",
    "        conn.commit()\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Something went wrong:\", err)\n",
    "    finally:\n",
    "        if conn.is_connected():\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "# My database and table name\n",
    "SQL_DB = \"bax422_final_price1\"\n",
    "SQL_TABLE_NAME = \"uber_eats_price1\"\n",
    "\n",
    "# SQL table structure\n",
    "SQL_TABLE_USER_INFO = \"\"\"\n",
    "(\n",
    "    id VARCHAR(100) PRIMARY KEY,\n",
    "    name VARCHAR(500),\n",
    "    address1 VARCHAR(500),\n",
    "    address2 VARCHAR(100),\n",
    "    city VARCHAR(100),\n",
    "    zip_code INT,\n",
    "    review_count VARCHAR(100),\n",
    "    categories VARCHAR(500),\n",
    "    rating INT,\n",
    "    price VARCHAR(10)\n",
    "    \n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Create your database and table\n",
    "create_sql_table(SQL_DB, SQL_TABLE_NAME, SQL_TABLE_USER_INFO)\n",
    "\n",
    "\n",
    "\n",
    "#Converting dataframe uber_eats_1 to dictionary to  pass it through insert_into function\n",
    "#uber_eats_1_dict = uber_eats_1.to_dict(orient = 'records')\n",
    "\n",
    "#Insert data into the databse\n",
    "for i in range(300):\n",
    "    data_dict = {\n",
    "        'id' : id[i],\n",
    "        'name' : retaurant_names[i],\n",
    "        'address1' : addresses[i],\n",
    "        'address2' : '',\n",
    "        'city' : ' San Francisco',\n",
    "        'zip_code' : zipcodes[i],\n",
    "        'review_count' : reviews[i],\n",
    "        'categories' : cuisine_list[i],\n",
    "        'rating': ratings[i],\n",
    "        'price' :'$'\n",
    "\n",
    "    }\n",
    "    insert_data_dict(SQL_DB, SQL_TABLE_NAME, data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643ded4-76cf-4679-853c-ccf6a47c0c7d",
   "metadata": {},
   "source": [
    "## Uber eats 2 dollar restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "430ae084-0e32-4adc-82ba-a0ca099a855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an isntance for chrome webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Navigating to Uber eats\n",
    "driver.get('https://www.ubereats.com/find-near-me/san-francisco-ca/food') \n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "dollar_2 = driver.find_elements(By.CSS_SELECTOR, \"[data-baseweb='button']\")\n",
    "dollar_2[1].click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#creating the directory\n",
    "import os\n",
    "directory = 'Uber Eats Web scrapping'\n",
    "\n",
    "#Checking if the directory exists\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "#Saving the web page\n",
    "html_source = driver.page_source\n",
    "with open(os.path.join(directory,'Uber_Eats_2_dollar_rest.html'), 'w', encoding='utf-8') as file:\n",
    "    file.write(html_source)\n",
    "\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a5ff745-ff7e-4ae7-90ec-d7deb83850f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "#Opening the page and parsing into html.\n",
    "from bs4 import BeautifulSoup\n",
    "with open(os.path.join(directory,'Uber_Eats_2_dollar_rest.html'), 'r', encoding='utf-8') as file:\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "#Using beautiful soup to extract required information\n",
    "\n",
    "#Starting with storing all the data for each restaurant in a list object\n",
    "output_list_2 = []\n",
    "for x in soup.findAll('div', class_ = 'al br am l0 lw'):\n",
    "    output = x.text\n",
    "    output_list_2.append(output)\n",
    "\n",
    "#print(output_list_2)\n",
    "\n",
    "#Now extracting restaurant name by extracting all the values before the $ sign in each element. We will iterate over each object\n",
    "retaurant_names_2 = []\n",
    "\n",
    "for item in output_list_2:\n",
    "    #find the position of dollar sign\n",
    "    dollar_index = item.find('$')\n",
    "    \n",
    "    if dollar_index != -1:\n",
    "        #Extract the restuarant name before '$' sign\n",
    "        retaurant_name = item[:dollar_index].strip()\n",
    "        retaurant_names_2.append(retaurant_name)\n",
    "\n",
    "#print(retaurant_names)\n",
    "print(len(retaurant_names_2))\n",
    "\n",
    "\n",
    "#Now extracting address by extracting information between 'Location marker' and 'Delivery..'. We will iterate over each object\n",
    "addresses_2 = []\n",
    "\n",
    "for item in output_list_2:\n",
    "    #find the position of Location Marker\n",
    "    lm_index = item.find('Location marker')\n",
    "    \n",
    "    if lm_index != -1:\n",
    "        #find the position of 'Delivery'\n",
    "        delivery_index = item.find('Delivery')\n",
    "        #Extract the address info\n",
    "        addresse = item[lm_index + len('Location Marker') :delivery_index].strip()\n",
    "        addresses_2.append(addresse)\n",
    "\n",
    "#print(addresses)\n",
    "print(len(addresses_2))\n",
    "\n",
    "#Now extracting zipcodes from addresses using regex\n",
    "zipcodes_2 = []\n",
    "zip_pattern = r'\\b\\d{5}(?:-\\d{4})?\\b'\n",
    "\n",
    "for address in addresses_2:\n",
    "    match = re.search(zip_pattern, address)\n",
    "    \n",
    "    if match:\n",
    "        zipcodes_2.append(match.group())\n",
    "    else:\n",
    "        zipcodes_2.append(0)\n",
    "        \n",
    "#print(zipcodes)\n",
    "print(len(zipcodes_2))\n",
    "\n",
    "#Now fetching the details of review_count using regex\n",
    "reviews_2 = []\n",
    "\n",
    "review_pattern = re.compile(r'\\((\\d+\\+?) ratings\\)')\n",
    "\n",
    "#Iterate over output_list\n",
    "for element in output_list_2:\n",
    "    #Search for 'ratings' in the element\n",
    "    match = review_pattern.search(element)\n",
    "    if match:\n",
    "        #If ratings found, extract the number within the brackets\n",
    "        review = match.group(1)\n",
    "        reviews_2.append(review)\n",
    "    else:\n",
    "        #If rating not found, return 'new'\n",
    "        reviews_2.append('new')\n",
    "\n",
    "#print(reviews)\n",
    "print(len(reviews_2))\n",
    "\n",
    "#Now extracting cuisine form this list\n",
    "cuisine_list_2 = []\n",
    "\n",
    "#Iterate over each element in output_list\n",
    "for element in output_list_2:\n",
    "    #Search for the substring after 'Circle i' using regex\n",
    "    match = re.search(r'Circle i(\\w+)(?=\\W|$)', element)\n",
    "    if match:\n",
    "        cuicine_info = match.group(1)\n",
    "        #split the cuicine info by non-alphanumeric characters and filter out empty strings\n",
    "        cuisines = [c.strip() for c in re.split(r'\\W+', cuicine_info) if c.strip()]\n",
    "        cuisine_list_2.append(cuisines)\n",
    "   \n",
    "#print(cuisine_list)\n",
    "print(len(cuisine_list_2))\n",
    "\n",
    "#Now extracting the rating informaation using regex \n",
    "rating_pattern = r'(\\d+(\\.\\d+)?)\\s*\\([0-9]+\\s*ratings\\)'\n",
    "\n",
    "ratings_2 = []\n",
    "#Iterate over output_list\n",
    "for element in output_list_2:\n",
    "    match = re.search(rating_pattern, element)\n",
    "    if match:\n",
    "        rating = match.group(1)\n",
    "        ratings_2.append(rating)\n",
    "    else:\n",
    "        ratings_2.append('0')\n",
    "\n",
    "#print(ratings)\n",
    "print(len(ratings_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae4338c5-58e3-483a-be3f-9cacadd9ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': ('ad92cdf1fc', 'Gluten Free Pizza Garden - SOMA', '60 Morris St, San Francisco, CA 94107', '', ' San Francisco', '94107', 'new', 'PizzaAmericanItalianGluten', '0', '$')}\n"
     ]
    }
   ],
   "source": [
    "#Creating a data dictionary\n",
    "\n",
    "#Creating unique id\n",
    "id_2 = [uuid.uuid4().hex[:10] for _ in range(300)]\n",
    "\n",
    "data_dict_2 = {\n",
    "    'id': id_2,\n",
    "    'name' : retaurant_names_2,\n",
    "    'Address' : addresses_2,\n",
    "    'city': 'San Francisco',\n",
    "    'zip_code': zipcodes_2,\n",
    "    'review_count': reviews_2,\n",
    "    'categories': cuisine_list_2,\n",
    "    'rating': ratings_2,\n",
    "    'price': '$$'\n",
    "\n",
    "}\n",
    "\n",
    "data = dict(zip(data_dict.keys(), zip(*data_dict.values())))\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbb57811-43e0-4362-9ddf-ad04a782126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong: 1265 (01000): Data truncated for column 'zip_code' at row 1\n"
     ]
    }
   ],
   "source": [
    "# Function to create a SQL table\n",
    "def create_sql_table(db_name, table_name, table_info):\n",
    "    try:\n",
    "        # Connect to server\n",
    "        conn = mysql.connector.connect(host='127.0.0.1',\n",
    "                                       port = '3306',\n",
    "                                       user='root',\n",
    "                                       password='Pvv@399051')\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Create database if it doesn't exist\n",
    "        cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "        \n",
    "        # Create table if it doesn't exist\n",
    "        cursor.execute(f\"CREATE TABLE IF NOT EXISTS {db_name}.{table_name} {table_info}\")\n",
    "        \n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Something went wrong:\", err)\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# Function to insert data into the table\n",
    "def insert_data_dict(db_name, table_name, data_dict):\n",
    "    try:\n",
    "        #Connect to MySQL database\n",
    "        conn = mysql.connector.connect(host='127.0.0.1',\n",
    "                                       port = '3306',\n",
    "                                       user='root',\n",
    "                                       password='Pvv@399051', database=db_name)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        #Find the max length among all values\n",
    "        max_length = max(len(lst) if isinstance(lst,list) else 1 for lst in data_dict.values())\n",
    "        \n",
    "        #Fill missing values with None or empty string\n",
    "        for key, value in data_dict.items():\n",
    "            if not isinstance(value,list):\n",
    "                data_dict[key] = [value] * max_length\n",
    "            elif len(value) < max_length:\n",
    "                data_dict[key].extend([None]*(max_legth - len(values)))\n",
    "                \n",
    "        #Create a parameterised sql query\n",
    "        placeholders = ', '.join(['%s'] * len(data_dict))\n",
    "        columns = ', '.join(data_dict.keys())\n",
    "        sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "        \n",
    "        #Prepare the data values to be inserted\n",
    "        values = [tuple(data_dict[key][i] for key in data_dict) for i in range(max_length)]\n",
    "        \n",
    "        #Execute the query with the values from the data dictionary\n",
    "        cursor.executemany(sql, values)\n",
    "\n",
    "        #Commit the transaction\n",
    "        conn.commit()\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Something went wrong:\", err)\n",
    "    finally:\n",
    "        if conn.is_connected():\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "# My database and table name\n",
    "SQL_DB = \"bax422_final_price1\"\n",
    "SQL_TABLE_NAME = \"uber_eats_price2\"\n",
    "\n",
    "# SQL table structure\n",
    "SQL_TABLE_USER_INFO = \"\"\"\n",
    "(\n",
    "    id VARCHAR(100) PRIMARY KEY,\n",
    "    name VARCHAR(500),\n",
    "    address1 VARCHAR(500),\n",
    "    address2 VARCHAR(100),\n",
    "    city VARCHAR(100),\n",
    "    zip_code INT,\n",
    "    review_count VARCHAR(100),\n",
    "    categories VARCHAR(500),\n",
    "    rating INT,\n",
    "    price VARCHAR(10)\n",
    "    \n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Create your database and table\n",
    "create_sql_table(SQL_DB, SQL_TABLE_NAME, SQL_TABLE_USER_INFO)\n",
    "\n",
    "\n",
    "\n",
    "#Converting dataframe uber_eats_1 to dictionary to  pass it through insert_into function\n",
    "#uber_eats_1_dict = uber_eats_1.to_dict(orient = 'records')\n",
    "\n",
    "#Insert data into the databse\n",
    "for i in range(300):\n",
    "    data_dict = {\n",
    "        'id' : id_2[i],\n",
    "        'name' : retaurant_names_2[i],\n",
    "        'address1' : addresses_2[i],\n",
    "        'address2' : '',\n",
    "        'city' : ' San Francisco',\n",
    "        'zip_code' : zipcodes_2[i],\n",
    "        'review_count' : reviews_2[i],\n",
    "        'categories' : cuisine_list_2[i],\n",
    "        'rating': ratings_2[i],\n",
    "        'price' :'$$'\n",
    "\n",
    "    }\n",
    "    insert_data_dict(SQL_DB, SQL_TABLE_NAME, data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510188a3-6d41-41d2-a5a3-0cbd4c1aeab0",
   "metadata": {},
   "source": [
    "## Uber eats 3 dollar restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0df7f699-c386-48cf-9556-3ca916c11de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an isntance for chrome webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Navigating to Uber eats\n",
    "driver.get('https://www.ubereats.com/find-near-me/san-francisco-ca/food') \n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "dollar_2 = driver.find_elements(By.CSS_SELECTOR, \"[data-baseweb='button']\")\n",
    "dollar_2[2].click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#creating the directory\n",
    "import os\n",
    "directory = 'Uber Eats Web scrapping'\n",
    "\n",
    "#Checking if the directory exists\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "#Saving the web page\n",
    "html_source = driver.page_source\n",
    "with open(os.path.join(directory,'Uber_Eats_3_dollar_rest.html'), 'w', encoding='utf-8') as file:\n",
    "    file.write(html_source)\n",
    "\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67e38fa9-5334-4cb3-8fc5-74b28b2915fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "#Opening the page and parsing into html.\n",
    "from bs4 import BeautifulSoup\n",
    "with open(os.path.join(directory,'Uber_Eats_3_dollar_rest.html'), 'r', encoding='utf-8') as file:\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "#Using beautiful soup to extract required information\n",
    "\n",
    "#Starting with storing all the data for each restaurant in a list object\n",
    "output_list_3 = []\n",
    "for x in soup.findAll('div', class_ = 'al br am l0 lw'):\n",
    "    output = x.text\n",
    "    output_list_3.append(output)\n",
    "\n",
    "#print(output_list_3)\n",
    "\n",
    "#Now extracting restaurant name by extracting all the values before the $ sign in each element. We will iterate over each object\n",
    "retaurant_names_3 = []\n",
    "\n",
    "for item in output_list_3:\n",
    "    #find the position of dollar sign\n",
    "    dollar_index = item.find('$')\n",
    "    \n",
    "    if dollar_index != -1:\n",
    "        #Extract the restuarant name before '$' sign\n",
    "        retaurant_name = item[:dollar_index].strip()\n",
    "        retaurant_names_3.append(retaurant_name)\n",
    "\n",
    "#print(retaurant_names)\n",
    "print(len(retaurant_names_3))\n",
    "\n",
    "\n",
    "#Now extracting address by extracting information between 'Location marker' and 'Delivery..'. We will iterate over each object\n",
    "addresses_3 = []\n",
    "\n",
    "for item in output_list_3:\n",
    "    #find the position of Location Marker\n",
    "    lm_index = item.find('Location marker')\n",
    "    \n",
    "    if lm_index != -1:\n",
    "        #find the position of 'Delivery'\n",
    "        delivery_index = item.find('Delivery')\n",
    "        #Extract the address info\n",
    "        addresse = item[lm_index + len('Location Marker') :delivery_index].strip()\n",
    "        addresses_3.append(addresse)\n",
    "\n",
    "#print(addresses)\n",
    "print(len(addresses_3))\n",
    "\n",
    "#Now extracting zipcodes from addresses using regex\n",
    "zipcodes_3 = []\n",
    "zip_pattern = r'\\b\\d{5}(?:-\\d{4})?\\b'\n",
    "\n",
    "for address in addresses_3:\n",
    "    match = re.search(zip_pattern, address)\n",
    "    \n",
    "    if match:\n",
    "        zipcodes_3.append(match.group())\n",
    "    else:\n",
    "        zipcodes_3.append(0)\n",
    "        \n",
    "#print(zipcodes)\n",
    "print(len(zipcodes_3))\n",
    "\n",
    "#Now fetching the details of review_count using regex\n",
    "reviews_3 = []\n",
    "\n",
    "review_pattern = re.compile(r'\\((\\d+\\+?) ratings\\)')\n",
    "\n",
    "#Iterate over output_list\n",
    "for element in output_list_3:\n",
    "    #Search for 'ratings' in the element\n",
    "    match = review_pattern.search(element)\n",
    "    if match:\n",
    "        #If ratings found, extract the number within the brackets\n",
    "        review = match.group(1)\n",
    "        reviews_3.append(review)\n",
    "    else:\n",
    "        #If rating not found, return 'new'\n",
    "        reviews_3.append('new')\n",
    "\n",
    "#print(reviews)\n",
    "print(len(reviews_3))\n",
    "\n",
    "#Now extracting cuisine form this list\n",
    "cuisine_list_3 = []\n",
    "\n",
    "#Iterate over each element in output_list\n",
    "for element in output_list_3:\n",
    "    #Search for the substring after 'Circle i' using regex\n",
    "    match = re.search(r'Circle i(\\w+)(?=\\W|$)', element)\n",
    "    if match:\n",
    "        cuicine_info = match.group(1)\n",
    "        #split the cuicine info by non-alphanumeric characters and filter out empty strings\n",
    "        cuisines = [c.strip() for c in re.split(r'\\W+', cuicine_info) if c.strip()]\n",
    "        cuisine_list_3.append(cuisines)\n",
    "   \n",
    "#print(cuisine_list)\n",
    "print(len(cuisine_list_3))\n",
    "\n",
    "#Now extracting the rating informaation using regex \n",
    "rating_pattern = r'(\\d+(\\.\\d+)?)\\s*\\([0-9]+\\s*ratings\\)'\n",
    "\n",
    "ratings_3 = []\n",
    "#Iterate over output_list\n",
    "for element in output_list_3:\n",
    "    match = re.search(rating_pattern, element)\n",
    "    if match:\n",
    "        rating = match.group(1)\n",
    "        ratings_3.append(rating)\n",
    "    else:\n",
    "        ratings_3.append('0')\n",
    "\n",
    "#print(ratings)\n",
    "print(len(ratings_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9299c9d9-c4a4-4186-a99b-7412db0d10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating unique id\n",
    "id_3 = [uuid.uuid4().hex[:10] for _ in range(39)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75a2b5d3-1351-4360-85a8-3f79b52dfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a SQL table\n",
    "def create_sql_table(db_name, table_name, table_info):\n",
    "    try:\n",
    "        # Connect to server\n",
    "        conn = mysql.connector.connect(host='127.0.0.1',\n",
    "                                       port = '3306',\n",
    "                                       user='root',\n",
    "                                       password='Pvv@399051')\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Create database if it doesn't exist\n",
    "        cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "        \n",
    "        # Create table if it doesn't exist\n",
    "        cursor.execute(f\"CREATE TABLE IF NOT EXISTS {db_name}.{table_name} {table_info}\")\n",
    "        \n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Something went wrong:\", err)\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# Function to insert data into the table\n",
    "def insert_data_dict(db_name, table_name, data_dict):\n",
    "    try:\n",
    "        #Connect to MySQL database\n",
    "        conn = mysql.connector.connect(host='127.0.0.1',\n",
    "                                       port = '3306',\n",
    "                                       user='root',\n",
    "                                       password='Pvv@399051', database=db_name)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        #Find the max length among all values\n",
    "        max_length = max(len(lst) if isinstance(lst,list) else 1 for lst in data_dict.values())\n",
    "        \n",
    "        #Fill missing values with None or empty string\n",
    "        for key, value in data_dict.items():\n",
    "            if not isinstance(value,list):\n",
    "                data_dict[key] = [value] * max_length\n",
    "            elif len(value) < max_length:\n",
    "                data_dict[key].extend([None]*(max_legth - len(values)))\n",
    "                \n",
    "        #Create a parameterised sql query\n",
    "        placeholders = ', '.join(['%s'] * len(data_dict))\n",
    "        columns = ', '.join(data_dict.keys())\n",
    "        sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "        \n",
    "        #Prepare the data values to be inserted\n",
    "        values = [tuple(data_dict[key][i] for key in data_dict) for i in range(max_length)]\n",
    "        \n",
    "        #Execute the query with the values from the data dictionary\n",
    "        cursor.executemany(sql, values)\n",
    "\n",
    "        #Commit the transaction\n",
    "        conn.commit()\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Something went wrong:\", err)\n",
    "    finally:\n",
    "        if conn.is_connected():\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "# My database and table name\n",
    "SQL_DB = \"bax422_final_price1\"\n",
    "SQL_TABLE_NAME = \"uber_eats_price3\"\n",
    "\n",
    "# SQL table structure\n",
    "SQL_TABLE_USER_INFO = \"\"\"\n",
    "(\n",
    "    id VARCHAR(100) PRIMARY KEY,\n",
    "    name VARCHAR(500),\n",
    "    address1 VARCHAR(500),\n",
    "    address2 VARCHAR(100),\n",
    "    city VARCHAR(100),\n",
    "    zip_code INT,\n",
    "    review_count VARCHAR(100),\n",
    "    categories VARCHAR(500),\n",
    "    rating INT,\n",
    "    price VARCHAR(10)\n",
    "    \n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Create your database and table\n",
    "create_sql_table(SQL_DB, SQL_TABLE_NAME, SQL_TABLE_USER_INFO)\n",
    "\n",
    "\n",
    "\n",
    "#Converting dataframe uber_eats_1 to dictionary to  pass it through insert_into function\n",
    "#uber_eats_1_dict = uber_eats_1.to_dict(orient = 'records')\n",
    "\n",
    "#Insert data into the databse\n",
    "for i in range(39):\n",
    "    data_dict = {\n",
    "        'id' : id_3[i],\n",
    "        'name' : retaurant_names_3[i],\n",
    "        'address1' : addresses_3[i],\n",
    "        'address2' : '',\n",
    "        'city' : ' San Francisco',\n",
    "        'zip_code' : zipcodes_3[i],\n",
    "        'review_count' : reviews_3[i],\n",
    "        'categories' : cuisine_list_3[i],\n",
    "        'rating': ratings_3[i],\n",
    "        'price' :'$$$'\n",
    "\n",
    "    }\n",
    "    insert_data_dict(SQL_DB, SQL_TABLE_NAME, data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeaffc1-f36d-47bf-8a0b-84de00700355",
   "metadata": {},
   "source": [
    "## Uber eats 4 dollar restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f848b69-c03b-478e-9a0b-4edf6862f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an isntance for chrome webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Navigating to Uber eats\n",
    "driver.get('https://www.ubereats.com/find-near-me/san-francisco-ca/food') \n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "dollar_4 = driver.find_elements(By.CSS_SELECTOR, \"[data-baseweb='button']\")\n",
    "dollar_4[3].click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#creating the directory\n",
    "import os\n",
    "directory = 'Uber Eats Web scrapping'\n",
    "\n",
    "#Checking if the directory exists\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "#Saving the web page\n",
    "html_source = driver.page_source\n",
    "with open(os.path.join(directory,'Uber_Eats_4_dollar_rest.html'), 'w', encoding='utf-8') as file:\n",
    "    file.write(html_source)\n",
    "\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d5130a5-6558-4bd7-801f-868fd06f1f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Opening the page and parsing into html.\n",
    "from bs4 import BeautifulSoup\n",
    "with open(os.path.join(directory,'Uber_Eats_4_dollar_rest.html'), 'r', encoding='utf-8') as file:\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "#Using beautiful soup to extract required information\n",
    "\n",
    "#Starting with storing all the data for each restaurant in a list object\n",
    "output_list_4 = []\n",
    "for x in soup.findAll('div', class_ = 'al br am l0 lw'):\n",
    "    output = x.text\n",
    "    output_list_4.append(output)\n",
    "\n",
    "#print(output_list_3)\n",
    "\n",
    "#Now extracting restaurant name by extracting all the values before the $ sign in each element. We will iterate over each object\n",
    "retaurant_names_4 = []\n",
    "\n",
    "for item in output_list_4:\n",
    "    #find the position of dollar sign\n",
    "    dollar_index = item.find('$')\n",
    "    \n",
    "    if dollar_index != -1:\n",
    "        #Extract the restuarant name before '$' sign\n",
    "        retaurant_name = item[:dollar_index].strip()\n",
    "        retaurant_names_4.append(retaurant_name)\n",
    "\n",
    "#print(retaurant_names)\n",
    "print(len(retaurant_names_4))\n",
    "\n",
    "\n",
    "#Now extracting address by extracting information between 'Location marker' and 'Delivery..'. We will iterate over each object\n",
    "addresses_4 = []\n",
    "\n",
    "for item in output_list_4:\n",
    "    #find the position of Location Marker\n",
    "    lm_index = item.find('Location marker')\n",
    "    \n",
    "    if lm_index != -1:\n",
    "        #find the position of 'Delivery'\n",
    "        delivery_index = item.find('Delivery')\n",
    "        #Extract the address info\n",
    "        addresse = item[lm_index + len('Location Marker') :delivery_index].strip()\n",
    "        addresses_4.append(addresse)\n",
    "\n",
    "#print(addresses)\n",
    "print(len(addresses_4))\n",
    "\n",
    "#Now extracting zipcodes from addresses using regex\n",
    "zipcodes_4 = []\n",
    "zip_pattern = r'\\b\\d{5}(?:-\\d{4})?\\b'\n",
    "\n",
    "for address in addresses_4:\n",
    "    match = re.search(zip_pattern, address)\n",
    "    \n",
    "    if match:\n",
    "        zipcodes_4.append(match.group())\n",
    "    else:\n",
    "        zipcodes_4.append(0)\n",
    "        \n",
    "#print(zipcodes)\n",
    "print(len(zipcodes_4))\n",
    "\n",
    "#Now fetching the details of review_count using regex\n",
    "reviews_4 = []\n",
    "\n",
    "review_pattern = re.compile(r'\\((\\d+\\+?) ratings\\)')\n",
    "\n",
    "#Iterate over output_list\n",
    "for element in output_list_4:\n",
    "    #Search for 'ratings' in the element\n",
    "    match = review_pattern.search(element)\n",
    "    if match:\n",
    "        #If ratings found, extract the number within the brackets\n",
    "        review = match.group(1)\n",
    "        reviews_4.append(review)\n",
    "    else:\n",
    "        #If rating not found, return 'new'\n",
    "        reviews_4.append('new')\n",
    "\n",
    "#print(reviews)\n",
    "print(len(reviews_4))\n",
    "\n",
    "#Now extracting cuisine form this list\n",
    "cuisine_list_4 = []\n",
    "\n",
    "#Iterate over each element in output_list\n",
    "for element in output_list_4:\n",
    "    #Search for the substring after 'Circle i' using regex\n",
    "    match = re.search(r'Circle i(\\w+)(?=\\W|$)', element)\n",
    "    if match:\n",
    "        cuicine_info = match.group(1)\n",
    "        #split the cuicine info by non-alphanumeric characters and filter out empty strings\n",
    "        cuisines = [c.strip() for c in re.split(r'\\W+', cuicine_info) if c.strip()]\n",
    "        cuisine_list_4.append(cuisines)\n",
    "   \n",
    "#print(cuisine_list)\n",
    "print(len(cuisine_list_4))\n",
    "\n",
    "#Now extracting the rating informaation using regex \n",
    "rating_pattern = r'(\\d+(\\.\\d+)?)\\s*\\([0-9]+\\s*ratings\\)'\n",
    "\n",
    "ratings_4 = []\n",
    "#Iterate over output_list\n",
    "for element in output_list_4:\n",
    "    match = re.search(rating_pattern, element)\n",
    "    if match:\n",
    "        rating = match.group(1)\n",
    "        ratings_4.append(rating)\n",
    "    else:\n",
    "        ratings_4.append('0')\n",
    "\n",
    "#print(ratings)\n",
    "print(len(ratings_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06279cfc-2509-4a01-82a8-bef3fce2569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating unique id\n",
    "id_4 = [uuid.uuid4().hex[:10] for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "707037fc-4d78-4d42-b0c6-04ae5ee77773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a SQL table\n",
    "def create_sql_table(db_name, table_name, table_info):\n",
    "    try:\n",
    "        # Connect to server\n",
    "        conn = mysql.connector.connect(host='127.0.0.1',\n",
    "                                       port = '3306',\n",
    "                                       user='root',\n",
    "                                       password='Pvv@399051')\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Create database if it doesn't exist\n",
    "        cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "        \n",
    "        # Create table if it doesn't exist\n",
    "        cursor.execute(f\"CREATE TABLE IF NOT EXISTS {db_name}.{table_name} {table_info}\")\n",
    "        \n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Something went wrong:\", err)\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# Function to insert data into the table\n",
    "def insert_data_dict(db_name, table_name, data_dict):\n",
    "    try:\n",
    "        #Connect to MySQL database\n",
    "        conn = mysql.connector.connect(host='127.0.0.1',\n",
    "                                       port = '3306',\n",
    "                                       user='root',\n",
    "                                       password='Pvv@399051', database=db_name)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        #Find the max length among all values\n",
    "        max_length = max(len(lst) if isinstance(lst,list) else 1 for lst in data_dict.values())\n",
    "        \n",
    "        #Fill missing values with None or empty string\n",
    "        for key, value in data_dict.items():\n",
    "            if not isinstance(value,list):\n",
    "                data_dict[key] = [value] * max_length\n",
    "            elif len(value) < max_length:\n",
    "                data_dict[key].extend([None]*(max_legth - len(values)))\n",
    "                \n",
    "        #Create a parameterised sql query\n",
    "        placeholders = ', '.join(['%s'] * len(data_dict))\n",
    "        columns = ', '.join(data_dict.keys())\n",
    "        sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "        \n",
    "        #Prepare the data values to be inserted\n",
    "        values = [tuple(data_dict[key][i] for key in data_dict) for i in range(max_length)]\n",
    "        \n",
    "        #Execute the query with the values from the data dictionary\n",
    "        cursor.executemany(sql, values)\n",
    "\n",
    "        #Commit the transaction\n",
    "        conn.commit()\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Something went wrong:\", err)\n",
    "    finally:\n",
    "        if conn.is_connected():\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "# My database and table name\n",
    "SQL_DB = \"bax422_final_price1\"\n",
    "SQL_TABLE_NAME = \"uber_eats_price4\"\n",
    "\n",
    "# SQL table structure\n",
    "SQL_TABLE_USER_INFO = \"\"\"\n",
    "(\n",
    "    id VARCHAR(100) PRIMARY KEY,\n",
    "    name VARCHAR(500),\n",
    "    address1 VARCHAR(500),\n",
    "    address2 VARCHAR(100),\n",
    "    city VARCHAR(100),\n",
    "    zip_code INT,\n",
    "    review_count VARCHAR(100),\n",
    "    categories VARCHAR(500),\n",
    "    rating INT,\n",
    "    price VARCHAR(10)\n",
    "    \n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Create your database and table\n",
    "create_sql_table(SQL_DB, SQL_TABLE_NAME, SQL_TABLE_USER_INFO)\n",
    "\n",
    "\n",
    "\n",
    "#Converting dataframe uber_eats_1 to dictionary to  pass it through insert_into function\n",
    "#uber_eats_1_dict = uber_eats_1.to_dict(orient = 'records')\n",
    "\n",
    "#Insert data into the databse\n",
    "for i in range(3):\n",
    "    data_dict = {\n",
    "        'id' : id_4[i],\n",
    "        'name' : retaurant_names_4[i],\n",
    "        'address1' : addresses_4[i],\n",
    "        'address2' : '',\n",
    "        'city' : ' San Francisco',\n",
    "        'zip_code' : zipcodes_4[i],\n",
    "        'review_count' : reviews_4[i],\n",
    "        'categories' : cuisine_list_4[i],\n",
    "        'rating': ratings_4[i],\n",
    "        'price' :'$$$$'\n",
    "\n",
    "    }\n",
    "    insert_data_dict(SQL_DB, SQL_TABLE_NAME, data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c7ee14-15ba-4a96-b9e6-e9e4b7ceef29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
